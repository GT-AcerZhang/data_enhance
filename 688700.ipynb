{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 解压花朵数据集\r\n",
    "!cd data/data34226 && unzip -qo scenes.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 解压预训练参数\n",
    "!cd data/data6489 && unzip -qo VGG16_pretrained.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['church', 'desert', 'ice', 'lawn', 'river']\n"
     ]
    }
   ],
   "source": [
    "# 预处理数据，将其转化为标准格式。同时将数据拆分成两份，以便训练和计算预估准确率\r\n",
    "import codecs\r\n",
    "import os\r\n",
    "import random\r\n",
    "import shutil\r\n",
    "from PIL import Image\r\n",
    "\r\n",
    "train_ratio = 4.0 / 5\r\n",
    "\r\n",
    "all_file_dir = 'data/data34226/scenes'\r\n",
    "class_list = [c for c in os.listdir(all_file_dir) if os.path.isdir(os.path.join(all_file_dir, c)) and not c.endswith('Set') and not c.startswith('.')]\r\n",
    "class_list.sort()\r\n",
    "print(class_list)\r\n",
    "train_image_dir = os.path.join(all_file_dir, \"trainImageSet\")\r\n",
    "if not os.path.exists(train_image_dir):\r\n",
    "    os.makedirs(train_image_dir)\r\n",
    "    \r\n",
    "eval_image_dir = os.path.join(all_file_dir, \"evalImageSet\")\r\n",
    "if not os.path.exists(eval_image_dir):\r\n",
    "    os.makedirs(eval_image_dir)\r\n",
    "\r\n",
    "train_file = codecs.open(os.path.join(all_file_dir, \"train.txt\"), 'w')\r\n",
    "eval_file = codecs.open(os.path.join(all_file_dir, \"eval.txt\"), 'w')\r\n",
    "\r\n",
    "with codecs.open(os.path.join(all_file_dir, \"label_list.txt\"), \"w\") as label_list:\r\n",
    "    label_id = 0\r\n",
    "    for class_dir in class_list:\r\n",
    "        label_list.write(\"{0}\\t{1}\\n\".format(label_id, class_dir))\r\n",
    "        image_path_pre = os.path.join(all_file_dir, class_dir)\r\n",
    "        for file in os.listdir(image_path_pre):\r\n",
    "            try:\r\n",
    "                img = Image.open(os.path.join(image_path_pre, file))\r\n",
    "                if random.uniform(0, 1) <= train_ratio:\r\n",
    "                    shutil.copyfile(os.path.join(image_path_pre, file), os.path.join(train_image_dir, file))\r\n",
    "                    train_file.write(\"{0}\\t{1}\\n\".format(os.path.join(train_image_dir, file), label_id))\r\n",
    "                else:\r\n",
    "                    shutil.copyfile(os.path.join(image_path_pre, file), os.path.join(eval_image_dir, file))\r\n",
    "                    eval_file.write(\"{0}\\t{1}\\n\".format(os.path.join(eval_image_dir, file), label_id))\r\n",
    "            except Exception as e:\r\n",
    "                pass\r\n",
    "                # 存在一些文件打不开，此处需要稍作清洗\r\n",
    "        label_id += 1\r\n",
    "            \r\n",
    "train_file.close()\r\n",
    "eval_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\r\n",
    "\"\"\"\r\n",
    "训练常用视觉基础网络，用于分类任务\r\n",
    "需要将训练图片，类别文件 label_list.txt 放置在同一个文件夹下\r\n",
    "程序会先读取 train.txt 文件获取类别数和图片数量\r\n",
    "\"\"\"\r\n",
    "from __future__ import absolute_import\r\n",
    "from __future__ import division\r\n",
    "from __future__ import print_function\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import time\r\n",
    "import math\r\n",
    "import paddle\r\n",
    "import paddle.fluid as fluid\r\n",
    "import codecs\r\n",
    "import logging\r\n",
    "\r\n",
    "from paddle.fluid.initializer import MSRA\r\n",
    "from paddle.fluid.initializer import Uniform\r\n",
    "from paddle.fluid.param_attr import ParamAttr\r\n",
    "from PIL import Image\r\n",
    "from PIL import ImageEnhance\r\n",
    "\r\n",
    "train_parameters = {\r\n",
    "    \"input_size\": [3, 224, 224],\r\n",
    "    \"class_dim\": -1,  # 分类数，会在初始化自定义 reader 的时候获得\r\n",
    "    \"image_count\": -1,  # 训练图片数量，会在初始化自定义 reader 的时候获得\r\n",
    "    \"label_dict\": {},\r\n",
    "    \"data_dir\": \"data/data34226/scenes\",  # 训练数据存储地址\r\n",
    "    \"train_file_list\": \"train.txt\",\r\n",
    "    \"label_file\": \"label_list.txt\",\r\n",
    "    \"save_freeze_dir\": \"./freeze-model\",\r\n",
    "    \"save_persistable_dir\": \"./persistable-params\",\r\n",
    "    \"continue_train\": False,        # 是否接着上一次保存的参数接着训练，优先级高于预训练模型\r\n",
    "    \"pretrained\": True,            # 是否使用预训练的模型\r\n",
    "    \"pretrained_dir\": \"data/data6489/VGG16_pretrained\", \r\n",
    "    \"mode\": \"train\",\r\n",
    "    \"num_epochs\": 120,\r\n",
    "    \"train_batch_size\": 64,\r\n",
    "    \"mean_rgb\": [127.5, 127.5, 127.5],  # 常用图片的三通道均值，通常来说需要先对训练数据做统计，此处仅取中间值\r\n",
    "    \"use_gpu\": True,\r\n",
    "    \"image_enhance_strategy\": {  # 图像增强相关策略\r\n",
    "        \"need_distort\": True,  # 是否启用图像颜色增强\r\n",
    "        \"need_rotate\": True,   # 是否需要增加随机角度\r\n",
    "        \"need_crop\": True,      # 是否要增加裁剪\r\n",
    "        \"need_flip\": True,      # 是否要增加水平随机翻转\r\n",
    "        \"hue_prob\": 0.5,\r\n",
    "        \"hue_delta\": 18,\r\n",
    "        \"contrast_prob\": 0.5,\r\n",
    "        \"contrast_delta\": 0.5,\r\n",
    "        \"saturation_prob\": 0.5,\r\n",
    "        \"saturation_delta\": 0.5,\r\n",
    "        \"brightness_prob\": 0.5,\r\n",
    "        \"brightness_delta\": 0.125\r\n",
    "    },\r\n",
    "    \"early_stop\": {\r\n",
    "        \"sample_frequency\": 50,\r\n",
    "        \"successive_limit\": 3,\r\n",
    "        \"good_acc1\": 0.92\r\n",
    "    },\r\n",
    "    \"rsm_strategy\": {\r\n",
    "        \"learning_rate\": 0.0005,\r\n",
    "        \"lr_epochs\": [20, 40, 60, 80, 100],\r\n",
    "        \"lr_decay\": [1, 0.5, 0.25, 0.1, 0.01, 0.002]\r\n",
    "    },\r\n",
    "    \"momentum_strategy\": {\r\n",
    "        \"learning_rate\": 0.0005,\r\n",
    "        \"lr_epochs\": [20, 40, 60, 80, 100],\r\n",
    "        \"lr_decay\": [1, 0.5, 0.25, 0.1, 0.01, 0.002]\r\n",
    "    },\r\n",
    "    \"sgd_strategy\": {\r\n",
    "        \"learning_rate\": 0.0005,\r\n",
    "        \"lr_epochs\": [20, 40, 60, 80, 100],\r\n",
    "        \"lr_decay\": [1, 0.5, 0.25, 0.1, 0.01, 0.002]\r\n",
    "    },\r\n",
    "    \"adam_strategy\": {\r\n",
    "        \"learning_rate\": 0.0005\r\n",
    "    }\r\n",
    "}\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "class VGGNet(object):\r\n",
    "    \"\"\"\r\n",
    "    vgg的网络类\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, layers=16):\r\n",
    "        \"\"\"\r\n",
    "        vgg网络构造函数\r\n",
    "        :param layers:\r\n",
    "        \"\"\"\r\n",
    "        self.layers = layers\r\n",
    "\r\n",
    "    def name(self):\r\n",
    "        \"\"\"\r\n",
    "        返回网络名字\r\n",
    "        :return:\r\n",
    "        \"\"\"\r\n",
    "        return 'vgg-net'\r\n",
    "\r\n",
    "    def net(self, input, class_dim=1000):\r\n",
    "        layers = self.layers\r\n",
    "        vgg_spec = {\r\n",
    "            11: ([1, 1, 2, 2, 2]),\r\n",
    "            13: ([2, 2, 2, 2, 2]),\r\n",
    "            16: ([2, 2, 3, 3, 3]),\r\n",
    "            19: ([2, 2, 4, 4, 4])\r\n",
    "        }\r\n",
    "        assert layers in vgg_spec.keys(), \\\r\n",
    "            \"supported layers are {} but input layer is {}\".format(vgg_spec.keys(), layers)\r\n",
    "\r\n",
    "        nums = vgg_spec[layers]\r\n",
    "        conv1 = self.conv_block(input, 64, nums[0], name=\"conv1_\")\r\n",
    "        conv2 = self.conv_block(conv1, 128, nums[1], name=\"conv2_\")\r\n",
    "        conv3 = self.conv_block(conv2, 256, nums[2], name=\"conv3_\")\r\n",
    "        conv4 = self.conv_block(conv3, 512, nums[3], name=\"conv4_\")\r\n",
    "        conv5 = self.conv_block(conv4, 512, nums[4], name=\"conv5_\")\r\n",
    "\r\n",
    "        fc_dim = 4096\r\n",
    "        fc_name = [\"fc6\", \"fc7\", \"fc8\"]\r\n",
    "        fc1 = fluid.layers.fc(\r\n",
    "            input=conv5,\r\n",
    "            size=fc_dim,\r\n",
    "            act='relu',\r\n",
    "            param_attr=fluid.param_attr.ParamAttr(name=fc_name[0] + \"_weights\"),\r\n",
    "            bias_attr=fluid.param_attr.ParamAttr(name=fc_name[0] + \"_offset\"))\r\n",
    "        fc1 = fluid.layers.dropout(x=fc1, dropout_prob=0.5)\r\n",
    "        fc2 = fluid.layers.fc(\r\n",
    "            input=fc1,\r\n",
    "            size=fc_dim,\r\n",
    "            act='relu',\r\n",
    "            param_attr=fluid.param_attr.ParamAttr(name=fc_name[1] + \"_weights\"),\r\n",
    "            bias_attr=fluid.param_attr.ParamAttr(name=fc_name[1] + \"_offset\"))\r\n",
    "        fc2 = fluid.layers.dropout(x=fc2, dropout_prob=0.5)\r\n",
    "        out = fluid.layers.fc(\r\n",
    "            input=fc2,\r\n",
    "            size=class_dim,\r\n",
    "            act='softmax',\r\n",
    "            param_attr=fluid.param_attr.ParamAttr(name=fc_name[2] + \"_weights\"),\r\n",
    "            bias_attr=fluid.param_attr.ParamAttr(name=fc_name[2] + \"_offset\"))\r\n",
    "\r\n",
    "        return out\r\n",
    "\r\n",
    "    def conv_block(self, input, num_filter, groups, name=None):\r\n",
    "        conv = input\r\n",
    "        for i in range(groups):\r\n",
    "            conv = fluid.layers.conv2d(\r\n",
    "                input=conv,\r\n",
    "                num_filters=num_filter,\r\n",
    "                filter_size=3,\r\n",
    "                stride=1,\r\n",
    "                padding=1,\r\n",
    "                act='relu',\r\n",
    "                param_attr=fluid.param_attr.ParamAttr(\r\n",
    "                    name=name + str(i + 1) + \"_weights\"),\r\n",
    "                bias_attr=fluid.param_attr.ParamAttr(\r\n",
    "                    name=name + str(i + 1) + \"_offset\"))\r\n",
    "        return fluid.layers.pool2d(\r\n",
    "            input=conv, pool_size=2, pool_type='max', pool_stride=2)\r\n",
    "\r\n",
    "\r\n",
    "def init_log_config():\r\n",
    "    \"\"\"\r\n",
    "    初始化日志相关配置\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    global logger\r\n",
    "    logger = logging.getLogger()\r\n",
    "    logger.setLevel(logging.INFO)\r\n",
    "    log_path = os.path.join(os.getcwd(), 'logs')\r\n",
    "    if not os.path.exists(log_path):\r\n",
    "        os.makedirs(log_path)\r\n",
    "    log_name = os.path.join(log_path, 'train.log')\r\n",
    "    sh = logging.StreamHandler()\r\n",
    "    fh = logging.FileHandler(log_name, mode='w')\r\n",
    "    fh.setLevel(logging.DEBUG)\r\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s\")\r\n",
    "    fh.setFormatter(formatter)\r\n",
    "    sh.setFormatter(formatter)\r\n",
    "    logger.addHandler(sh)\r\n",
    "    logger.addHandler(fh)\r\n",
    "\r\n",
    "\r\n",
    "def init_train_parameters():\r\n",
    "    \"\"\"\r\n",
    "    初始化训练参数，主要是初始化图片数量，类别数\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    train_file_list = os.path.join(train_parameters['data_dir'], train_parameters['train_file_list'])\r\n",
    "    label_list = os.path.join(train_parameters['data_dir'], train_parameters['label_file'])\r\n",
    "    index = 0\r\n",
    "    with codecs.open(label_list, encoding='utf-8') as flist:\r\n",
    "        lines = [line.strip() for line in flist]\r\n",
    "        for line in lines:\r\n",
    "            parts = line.strip().split()\r\n",
    "            train_parameters['label_dict'][parts[1]] = int(parts[0])\r\n",
    "            index += 1\r\n",
    "        train_parameters['class_dim'] = index\r\n",
    "    with codecs.open(train_file_list, encoding='utf-8') as flist:\r\n",
    "        lines = [line.strip() for line in flist]\r\n",
    "        train_parameters['image_count'] = len(lines)\r\n",
    "\r\n",
    "\r\n",
    "def resize_img(img, target_size):\r\n",
    "    \"\"\"\r\n",
    "    强制缩放图片\r\n",
    "    :param img:\r\n",
    "    :param target_size:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    target_size = input_size\r\n",
    "    img = img.resize((target_size[1], target_size[2]), Image.BILINEAR)\r\n",
    "    return img\r\n",
    "\r\n",
    "\r\n",
    "def random_crop(img, scale=[0.08, 1.0], ratio=[3. / 4., 4. / 3.]):\r\n",
    "    aspect_ratio = math.sqrt(np.random.uniform(*ratio))\r\n",
    "    w = 1. * aspect_ratio\r\n",
    "    h = 1. / aspect_ratio\r\n",
    "\r\n",
    "    bound = min((float(img.size[0]) / img.size[1]) / (w**2),\r\n",
    "                (float(img.size[1]) / img.size[0]) / (h**2))\r\n",
    "    scale_max = min(scale[1], bound)\r\n",
    "    scale_min = min(scale[0], bound)\r\n",
    "\r\n",
    "    target_area = img.size[0] * img.size[1] * np.random.uniform(scale_min,\r\n",
    "                                                                scale_max)\r\n",
    "    target_size = math.sqrt(target_area)\r\n",
    "    w = int(target_size * w)\r\n",
    "    h = int(target_size * h)\r\n",
    "\r\n",
    "    i = np.random.randint(0, img.size[0] - w + 1)\r\n",
    "    j = np.random.randint(0, img.size[1] - h + 1)\r\n",
    "\r\n",
    "    img = img.crop((i, j, i + w, j + h))\r\n",
    "    img = img.resize((train_parameters['input_size'][1], train_parameters['input_size'][2]), Image.BILINEAR)\r\n",
    "    return img\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "def rotate_image(img):\r\n",
    "    \"\"\"\r\n",
    "    图像增强，增加随机旋转角度\r\n",
    "    \"\"\"\r\n",
    "    angle = np.random.randint(-14, 15)\r\n",
    "    img = img.rotate(angle)\r\n",
    "    return img\r\n",
    "\r\n",
    "\r\n",
    "def random_brightness(img):\r\n",
    "    \"\"\"\r\n",
    "    图像增强，亮度调整\r\n",
    "    :param img:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    prob = np.random.uniform(0, 1)\r\n",
    "    if prob < train_parameters['image_enhance_strategy']['brightness_prob']:\r\n",
    "        brightness_delta = train_parameters['image_enhance_strategy']['brightness_delta']\r\n",
    "        delta = np.random.uniform(-brightness_delta, brightness_delta) + 1\r\n",
    "        img = ImageEnhance.Brightness(img).enhance(delta)\r\n",
    "    return img\r\n",
    "\r\n",
    "\r\n",
    "def random_contrast(img):\r\n",
    "    \"\"\"\r\n",
    "    图像增强，对比度调整\r\n",
    "    :param img:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    prob = np.random.uniform(0, 1)\r\n",
    "    if prob < train_parameters['image_enhance_strategy']['contrast_prob']:\r\n",
    "        contrast_delta = train_parameters['image_enhance_strategy']['contrast_delta']\r\n",
    "        delta = np.random.uniform(-contrast_delta, contrast_delta) + 1\r\n",
    "        img = ImageEnhance.Contrast(img).enhance(delta)\r\n",
    "    return img\r\n",
    "\r\n",
    "\r\n",
    "def random_saturation(img):\r\n",
    "    \"\"\"\r\n",
    "    图像增强，饱和度调整\r\n",
    "    :param img:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    prob = np.random.uniform(0, 1)\r\n",
    "    if prob < train_parameters['image_enhance_strategy']['saturation_prob']:\r\n",
    "        saturation_delta = train_parameters['image_enhance_strategy']['saturation_delta']\r\n",
    "        delta = np.random.uniform(-saturation_delta, saturation_delta) + 1\r\n",
    "        img = ImageEnhance.Color(img).enhance(delta)\r\n",
    "    return img\r\n",
    "\r\n",
    "\r\n",
    "def random_hue(img):\r\n",
    "    \"\"\"\r\n",
    "    图像增强，色度调整\r\n",
    "    :param img:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    prob = np.random.uniform(0, 1)\r\n",
    "    if prob < train_parameters['image_enhance_strategy']['hue_prob']:\r\n",
    "        hue_delta = train_parameters['image_enhance_strategy']['hue_delta']\r\n",
    "        delta = np.random.uniform(-hue_delta, hue_delta)\r\n",
    "        img_hsv = np.array(img.convert('HSV'))\r\n",
    "        img_hsv[:, :, 0] = img_hsv[:, :, 0] + delta\r\n",
    "        img = Image.fromarray(img_hsv, mode='HSV').convert('RGB')\r\n",
    "    return img\r\n",
    "\r\n",
    "\r\n",
    "def distort_color(img):\r\n",
    "    \"\"\"\r\n",
    "    概率的图像增强\r\n",
    "    :param img:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    prob = np.random.uniform(0, 1)\r\n",
    "    # Apply different distort order\r\n",
    "    if prob < 0.35:\r\n",
    "        img = random_brightness(img)\r\n",
    "        img = random_contrast(img)\r\n",
    "        img = random_saturation(img)\r\n",
    "        img = random_hue(img)\r\n",
    "    elif prob < 0.7:\r\n",
    "        img = random_brightness(img)\r\n",
    "        img = random_saturation(img)\r\n",
    "        img = random_hue(img)\r\n",
    "        img = random_contrast(img)\r\n",
    "    return img\r\n",
    "\r\n",
    "\r\n",
    "def custom_image_reader(file_list, data_dir, mode):\r\n",
    "    \"\"\"\r\n",
    "    自定义用户图片读取器，先初始化图片种类，数量\r\n",
    "    :param file_list:\r\n",
    "    :param data_dir:\r\n",
    "    :param mode:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    with codecs.open(file_list) as flist:\r\n",
    "        lines = [line.strip() for line in flist]\r\n",
    "\r\n",
    "    def reader():\r\n",
    "        np.random.shuffle(lines)\r\n",
    "        for line in lines:\r\n",
    "            if mode == 'train' or mode == 'val':\r\n",
    "                img_path, label = line.split()\r\n",
    "                img = Image.open(img_path)\r\n",
    "                try:\r\n",
    "                    if img.mode != 'RGB':\r\n",
    "                        img = img.convert('RGB')\r\n",
    "                    if train_parameters['image_enhance_strategy']['need_distort'] == True:\r\n",
    "                        img = distort_color(img)\r\n",
    "                    if train_parameters['image_enhance_strategy']['need_rotate'] == True:\r\n",
    "                        img = rotate_image(img)\r\n",
    "                    if train_parameters['image_enhance_strategy']['need_crop'] == True:\r\n",
    "                        img = random_crop(img, train_parameters['input_size'])\r\n",
    "                    if train_parameters['image_enhance_strategy']['need_flip'] == True:\r\n",
    "                        mirror = int(np.random.uniform(0, 2))\r\n",
    "                        if mirror == 1:\r\n",
    "                            img = img.transpose(Image.FLIP_LEFT_RIGHT)\r\n",
    "                    # HWC--->CHW && normalized\r\n",
    "                    img = np.array(img).astype('float32')\r\n",
    "                    img -= train_parameters['mean_rgb']\r\n",
    "                    img = img.transpose((2, 0, 1))  # HWC to CHW\r\n",
    "                    img *= 0.007843                 # 像素值归一化\r\n",
    "                    yield img, int(label)\r\n",
    "                except Exception as e:\r\n",
    "                    pass                            # 以防某些图片读取处理出错，加异常处理\r\n",
    "            elif mode == 'test':\r\n",
    "                img_path = os.path.join(data_dir, line)\r\n",
    "                img = Image.open(img_path)\r\n",
    "                if img.mode != 'RGB':\r\n",
    "                    img = img.convert('RGB')\r\n",
    "                img = resize_img(img, train_parameters['input_size'])\r\n",
    "                # HWC--->CHW && normalized\r\n",
    "                img = np.array(img).astype('float32')\r\n",
    "                img -= train_parameters['mean_rgb']\r\n",
    "                img = img.transpose((2, 0, 1))  # HWC to CHW\r\n",
    "                img *= 0.007843  # 像素值归一化\r\n",
    "                yield img\r\n",
    "\r\n",
    "    return reader\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "\r\n",
    "def optimizer_momentum_setting():\r\n",
    "    \"\"\"\r\n",
    "    阶梯型的学习率适合比较大规模的训练数据\r\n",
    "    \"\"\"\r\n",
    "    learning_strategy = train_parameters['momentum_strategy']\r\n",
    "    batch_size = train_parameters[\"train_batch_size\"]\r\n",
    "    iters = train_parameters[\"image_count\"] // batch_size\r\n",
    "    lr = learning_strategy['learning_rate']\r\n",
    "\r\n",
    "    boundaries = [i * iters for i in learning_strategy[\"lr_epochs\"]]\r\n",
    "    values = [i * lr for i in learning_strategy[\"lr_decay\"]]\r\n",
    "    learning_rate = fluid.layers.piecewise_decay(boundaries, values)\r\n",
    "    optimizer = fluid.optimizer.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\r\n",
    "    return optimizer\r\n",
    "\r\n",
    "\r\n",
    "def optimizer_rms_setting():\r\n",
    "    \"\"\"\r\n",
    "    阶梯型的学习率适合比较大规模的训练数据\r\n",
    "    \"\"\"\r\n",
    "    batch_size = train_parameters[\"train_batch_size\"]\r\n",
    "    iters = train_parameters[\"image_count\"] // batch_size\r\n",
    "    learning_strategy = train_parameters['rsm_strategy']\r\n",
    "    lr = learning_strategy['learning_rate']\r\n",
    "\r\n",
    "    boundaries = [i * iters for i in learning_strategy[\"lr_epochs\"]]\r\n",
    "    values = [i * lr for i in learning_strategy[\"lr_decay\"]]\r\n",
    "\r\n",
    "    optimizer = fluid.optimizer.RMSProp(\r\n",
    "        learning_rate=fluid.layers.piecewise_decay(boundaries, values))\r\n",
    "\r\n",
    "    return optimizer\r\n",
    "\r\n",
    "\r\n",
    "def optimizer_sgd_setting():\r\n",
    "    \"\"\"\r\n",
    "    loss下降相对较慢，但是最终效果不错，阶梯型的学习率适合比较大规模的训练数据\r\n",
    "    \"\"\"\r\n",
    "    learning_strategy = train_parameters['sgd_strategy']\r\n",
    "    batch_size = train_parameters[\"train_batch_size\"]\r\n",
    "    iters = train_parameters[\"image_count\"] // batch_size\r\n",
    "    lr = learning_strategy['learning_rate']\r\n",
    "\r\n",
    "    boundaries = [i * iters for i in learning_strategy[\"lr_epochs\"]]\r\n",
    "    values = [i * lr for i in learning_strategy[\"lr_decay\"]]\r\n",
    "    learning_rate = fluid.layers.piecewise_decay(boundaries, values)\r\n",
    "    optimizer = fluid.optimizer.SGD(learning_rate=learning_rate)\r\n",
    "    return optimizer\r\n",
    "\r\n",
    "\r\n",
    "def optimizer_adam_setting():\r\n",
    "    \"\"\"\r\n",
    "    能够比较快速的降低 loss，但是相对后期乏力\r\n",
    "    \"\"\"\r\n",
    "    learning_strategy = train_parameters['adam_strategy']\r\n",
    "    learning_rate = learning_strategy['learning_rate']\r\n",
    "    optimizer = fluid.optimizer.Adam(learning_rate=learning_rate)\r\n",
    "    return optimizer\r\n",
    "\r\n",
    "\r\n",
    "def load_params(exe, program):\r\n",
    "    if train_parameters['continue_train'] and os.path.exists(train_parameters['save_persistable_dir']):\r\n",
    "        logger.info('load params from retrain model')\r\n",
    "        fluid.io.load_persistables(executor=exe,\r\n",
    "                                   dirname=train_parameters['save_persistable_dir'],\r\n",
    "                                   main_program=program)\r\n",
    "    elif train_parameters['pretrained'] and os.path.exists(train_parameters['pretrained_dir']):\r\n",
    "        logger.info('load params from pretrained model')\r\n",
    "        def if_exist(var):\r\n",
    "            return os.path.exists(os.path.join(train_parameters['pretrained_dir'], var.name))\r\n",
    "\r\n",
    "        fluid.io.load_vars(exe, train_parameters['pretrained_dir'], main_program=program,\r\n",
    "                           predicate=if_exist)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "def train():\r\n",
    "    train_prog = fluid.Program()\r\n",
    "    train_startup = fluid.Program()\r\n",
    "    logger.info(\"create prog success\")\r\n",
    "    logger.info(\"train config: %s\", str(train_parameters))\r\n",
    "    logger.info(\"build input custom reader and data feeder\")\r\n",
    "    file_list = os.path.join(train_parameters['data_dir'], \"train.txt\")\r\n",
    "    mode = train_parameters['mode']\r\n",
    "    batch_reader = paddle.batch(custom_image_reader(file_list, train_parameters['data_dir'], mode),\r\n",
    "                                batch_size=train_parameters['train_batch_size'],\r\n",
    "                                drop_last=False)\r\n",
    "    place = fluid.CUDAPlace(0) if train_parameters['use_gpu'] else fluid.CPUPlace()\r\n",
    "    # 定义输入数据的占位符\r\n",
    "    img = fluid.layers.data(name='img', shape=train_parameters['input_size'], dtype='float32')\r\n",
    "    label = fluid.layers.data(name='label', shape=[1], dtype='int64')\r\n",
    "    feeder = fluid.DataFeeder(feed_list=[img, label], place=place)\r\n",
    "\r\n",
    "    # 选取不同的网络\r\n",
    "    logger.info(\"build newwork\")\r\n",
    "    model = VGGNet(layers=16)\r\n",
    "    out = model.net(input=img, class_dim=train_parameters['class_dim'])\r\n",
    "    cost = fluid.layers.cross_entropy(out, label)\r\n",
    "    avg_cost = fluid.layers.mean(x=cost)\r\n",
    "    acc_top1 = fluid.layers.accuracy(input=out, label=label, k=1)\r\n",
    "    # 选取不同的优化器\r\n",
    "    optimizer = optimizer_rms_setting()\r\n",
    "    # optimizer = optimizer_momentum_setting()\r\n",
    "    # optimizer = optimizer_sgd_setting()\r\n",
    "    # optimizer = optimizer_adam_setting()\r\n",
    "    optimizer.minimize(avg_cost)\r\n",
    "    exe = fluid.Executor(place)\r\n",
    "\r\n",
    "    main_program = fluid.default_main_program()\r\n",
    "    exe.run(fluid.default_startup_program())\r\n",
    "    train_fetch_list = [avg_cost.name, acc_top1.name, out.name]\r\n",
    "    \r\n",
    "    load_params(exe, main_program)\r\n",
    "\r\n",
    "    # 训练循环主体\r\n",
    "    stop_strategy = train_parameters['early_stop']\r\n",
    "    successive_limit = stop_strategy['successive_limit']\r\n",
    "    sample_freq = stop_strategy['sample_frequency']\r\n",
    "    good_acc1 = stop_strategy['good_acc1']\r\n",
    "    successive_count = 0\r\n",
    "    stop_train = False\r\n",
    "    total_batch_count = 0\r\n",
    "    print(\"========================================================  \")\r\n",
    "    for pass_id in range(train_parameters[\"num_epochs\"]):   #120\r\n",
    "        logger.info(\"current pass: %d, start read image\", pass_id)\r\n",
    "        batch_id = 0\r\n",
    "        for step_id, data in enumerate(batch_reader()):\r\n",
    "            t1 = time.time()\r\n",
    "            loss, acc1, pred_ot = exe.run(main_program,\r\n",
    "                                          feed=feeder.feed(data),\r\n",
    "                                          fetch_list=train_fetch_list)\r\n",
    "            t2 = time.time()\r\n",
    "            batch_id += 1\r\n",
    "            total_batch_count += 1\r\n",
    "            period = t2 - t1\r\n",
    "            loss = np.mean(np.array(loss))\r\n",
    "            acc1 = np.mean(np.array(acc1))\r\n",
    "            if batch_id % 10 == 0:\r\n",
    "                logger.info(\"Pass {0}, trainbatch {1}, loss {2}, acc1 {3}, time {4}\".format(pass_id, batch_id, loss, acc1,\"%2.2f sec\" % period))\r\n",
    "            # 简单的提前停止策略，认为连续达到某个准确率就可以停止了\r\n",
    "            if acc1 >= good_acc1:\r\n",
    "                successive_count += 1\r\n",
    "                logger.info(\"current acc1 {0} meets good {1}, successive count {2}\".format(acc1, good_acc1, successive_count))\r\n",
    "                fluid.io.save_inference_model(dirname=train_parameters['save_freeze_dir'],\r\n",
    "                                              feeded_var_names=['img'],\r\n",
    "                                              target_vars=[out],\r\n",
    "                                              main_program=main_program,\r\n",
    "                                              executor=exe)\r\n",
    "                if successive_count >= successive_limit:\r\n",
    "                    logger.info(\"end training\")\r\n",
    "                    stop_train = True\r\n",
    "                    break\r\n",
    "            else:\r\n",
    "                successive_count = 0\r\n",
    "\r\n",
    "            # 通用的保存策略，减小意外停止的损失\r\n",
    "            if total_batch_count % sample_freq == 0:\r\n",
    "                logger.info(\"temp save {0} batch train result, current acc1 {1}\".format(total_batch_count, acc1))\r\n",
    "                fluid.io.save_persistables(dirname=train_parameters['save_persistable_dir'],\r\n",
    "                                           main_program=main_program,\r\n",
    "                                           executor=exe)\r\n",
    "        if stop_train:\r\n",
    "            break\r\n",
    "    logger.info(\"training till last epcho, end training\")\r\n",
    "    fluid.io.save_persistables(dirname=train_parameters['save_persistable_dir'],\r\n",
    "                                           main_program=main_program,\r\n",
    "                                           executor=exe)\r\n",
    "    fluid.io.save_inference_model(dirname=train_parameters['save_freeze_dir'],\r\n",
    "                                              feeded_var_names=['img'],\r\n",
    "                                              target_vars=[out],\r\n",
    "                                              main_program=main_program.clone(for_test=True),\r\n",
    "                                              executor=exe)\r\n",
    "\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    init_log_config()\r\n",
    "    init_train_parameters()\r\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import     \r\n",
    "from __future__ import division     \r\n",
    "from __future__ import print_function     \r\n",
    "     \r\n",
    "import os     \r\n",
    "import numpy as np     \r\n",
    "import random     \r\n",
    "import time     \r\n",
    "import codecs     \r\n",
    "import sys     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total eval count:701 cost time:9.26 sec predict accuracy:0.7232524964336662\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "import functools     \r\n",
    "import math     \r\n",
    "import paddle     \r\n",
    "import paddle.fluid as fluid     \r\n",
    "from paddle.fluid import core     \r\n",
    "from paddle.fluid.param_attr import ParamAttr     \r\n",
    "from PIL import Image, ImageEnhance     \r\n",
    "     \r\n",
    "target_size = [3, 224, 224]     \r\n",
    "mean_rgb = [127.5, 127.5, 127.5]     \r\n",
    "data_dir = \"data/data34226/scenes\"     \r\n",
    "eval_file = \"eval.txt\"     \r\n",
    "use_gpu = True     \r\n",
    "place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()     \r\n",
    "exe = fluid.Executor(place)     \r\n",
    "save_freeze_dir = \"./freeze-model\"     \r\n",
    "[inference_program, feed_target_names, fetch_targets] = fluid.io.load_inference_model(dirname=save_freeze_dir, executor=exe)     \r\n",
    "# print(fetch_targets)     \r\n",
    "     \r\n",
    "     \r\n",
    "def crop_image(img, target_size):     \r\n",
    "    width, height = img.size     \r\n",
    "    w_start = (width - target_size[2]) / 2     \r\n",
    "    h_start = (height - target_size[1]) / 2     \r\n",
    "    w_end = w_start + target_size[2]     \r\n",
    "    h_end = h_start + target_size[1]     \r\n",
    "    img = img.crop((w_start, h_start, w_end, h_end))     \r\n",
    "    return img     \r\n",
    "     \r\n",
    "     \r\n",
    "def resize_img(img, target_size):     \r\n",
    "    ret = img.resize((target_size[1], target_size[2]), Image.BILINEAR)     \r\n",
    "    return ret     \r\n",
    "     \r\n",
    "     \r\n",
    "def read_image(img_path):     \r\n",
    "    img = Image.open(img_path)     \r\n",
    "    if img.mode != 'RGB':     \r\n",
    "        img = img.convert('RGB')     \r\n",
    "    img = crop_image(img, target_size)     \r\n",
    "    img = np.array(img).astype('float32')     \r\n",
    "    img -= mean_rgb     \r\n",
    "    img = img.transpose((2, 0, 1))  # HWC to CHW     \r\n",
    "    img *= 0.007843     \r\n",
    "    img = img[np.newaxis,:]     \r\n",
    "    return img     \r\n",
    "     \r\n",
    "     \r\n",
    "def infer(image_path):     \r\n",
    "    tensor_img = read_image(image_path)     \r\n",
    "    label = exe.run(inference_program, feed={feed_target_names[0]: tensor_img}, fetch_list=fetch_targets)     \r\n",
    "    return np.argmax(label)     \r\n",
    "     \r\n",
    "     \r\n",
    "def eval_all():     \r\n",
    "    eval_file_path = os.path.join(data_dir, eval_file)     \r\n",
    "    total_count = 0     \r\n",
    "    right_count = 0     \r\n",
    "    with codecs.open(eval_file_path, encoding='utf-8') as flist:      \r\n",
    "        lines = [line.strip() for line in flist]     \r\n",
    "        t1 = time.time()     \r\n",
    "        for line in lines:     \r\n",
    "            total_count += 1     \r\n",
    "            parts = line.strip().split()     \r\n",
    "            result = infer(parts[0])     \r\n",
    "            # print(\"infer result:{0} answer:{1}\".format(result, parts[1]))     \r\n",
    "            if str(result) == parts[1]:     \r\n",
    "                right_count += 1     \r\n",
    "        period = time.time() - t1     \r\n",
    "        print(\"total eval count:{0} cost time:{1} predict accuracy:{2}\".format(total_count, \"%2.2f sec\" % period, right_count / total_count))     \r\n",
    "     \r\n",
    "     \r\n",
    "if __name__ == '__main__':     \r\n",
    "    eval_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.6.2 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
