{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 试题说明\n",
    "\n",
    "### 任务描述\n",
    "近年来，随着人工智能的发展，其在语音识别、自然语言处理、图像与视频分析等诸多领域取得了巨大成功。随着政府对环境保护的呼吁，垃圾分类成为一个亟待解决的问题，本次竞赛将聚焦在垃圾图片的分类，利用人工智能技术，对居民生活垃圾图片进行检测，找出图片中有哪些类别的垃圾。\n",
    "要求参赛者给出一个算法或模型，对于给定的图片，检测出图片中的垃圾类别。给定图片数据，选手据此训练模型，为每张测试数据预测出最正确的类别。\n",
    "\n",
    "### 数据说明\n",
    "本竞赛所用训练和测试图片均来自生活场景。总共四十个类别，类别和标签对应关系在训练集中的dict文件里。图片中垃圾的类别，格式是“一级类别/二级类别”，二级类别是具体的垃圾物体类别，也就是训练数据中标注的类别，比如一次性快餐盒、果皮果肉、旧衣服等。一级类别有四种类别：可回收物、厨余垃圾、有害垃圾和其他垃圾。\n",
    "\n",
    "数据文件包括训练集(有标注)和测试集(无标注)，训练集的所有图片分别保存在train文件夹下面的0-39个文件夹中，文件名即类别标签，测试集共有400张待分类的垃圾图片在test文件夹下，testpath.txt保存了所有测试集文件的名称，格式为：name+\\n。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/cec625e7b61d459fa13ed2b822817bfd57030ad23c524f1ab93b3e7108d75d78)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/df06e2956f2044fab21fde2a9602abfdb9d4720861d54c66b2e079f3e64000a7)\n",
    "\n",
    "### 提交答案\n",
    "考试提交，需要提交**模型代码项目版本**和**结果文件**。结果文件为TXT文件格式，命名为model_result.txt，文件内的字段需要按照指定格式写入。\n",
    "\n",
    "提交结果的格式如下：\n",
    "1. 每个类别的行数和测试集原始数据行数应一一对应，不可乱序。\n",
    "2. 输出结果应检查是否为400行数据，否则成绩无效。\n",
    "3. 输出结果文件命名为model_result.txt，一行一个类别标签（数字）\n",
    "\n",
    "\n",
    "样例如下：\n",
    "\n",
    "···\n",
    "\n",
    "35\n",
    "\n",
    "3\n",
    "\n",
    "2\n",
    "\n",
    "37\n",
    "\n",
    "10\n",
    "\n",
    "3\n",
    "\n",
    "26\n",
    "\n",
    "4\n",
    "\n",
    "34\n",
    "\n",
    "21\n",
    "\n",
    "···\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 开始答题，解压数据\n",
    "### 数据集所在目录有可能发生改变，将\"data/data38817/\"替换为实际的数据集文件所在目录\n",
    "!unzip  -qo data/data38817/train.zip -d 'dataset/'\n",
    "!unzip  -qo data/data38817/test.zip -d  'dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "导入库\n",
    "'''\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import zipfile\n",
    "import random\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.dygraph import Linear\n",
    "from paddle.fluid.dygraph import Pool2D,Conv2D\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "参数配置\n",
    "'''\n",
    "import codecs\n",
    "import os\n",
    "\n",
    "\n",
    "train_parameters = {  \n",
    "    \"input_size\": [3, 224, 224],  \n",
    "    \"class_dim\": -1,  # 分类数，会在初始化自定义 reader 的时候获得  \n",
    "    \"image_count\": -1,  # 训练图片数量，会在初始化自定义 reader 的时候获得  \n",
    "    \"label_dict\": {},  \n",
    "    \"data_dir\": \"dataset\",  # 训练数据存储地址  \n",
    "    \"train_file_list\": \"train_list.txt\",  \n",
    "    \"evals_file_list\": \"evals_list.txt\", \n",
    "    \"tests_file_list\": \"testpath.txt\",\n",
    "    \"label_file\": \"label_list.txt\",  \n",
    "    \"save_persistable_dir\": \"./persistable-params/model\",  \n",
    "    #\"continue_train\": True,        # 是否接着上一次保存的参数接着训练，优先级高于预训练模型  \n",
    "    \"continue_train\": False,\n",
    "    \"num_epochs\": 2,                # 这里是演示，设置为训练2个epoch\n",
    "    \"train_batch_size\": 32, \n",
    "    \"dropout_prob\": 0.2,\n",
    "    \"dropout_seed\": None,   \n",
    "    \"network_vgg\": {               #VGG\n",
    "        \"layer\": 16                #VGG的层数\n",
    "    },                                            \n",
    "    \"network_resnet\": {            # ResNet\n",
    "        \"layer\": 50                # ResNet的层数\n",
    "    },  \n",
    "    \"result_dir\": \"output\",        # 数据结果存储地址  \n",
    "    \"infer_img\": 'dataset/test/test111.jpg',\n",
    "    \"mean_rgb\": [127.5, 127.5, 127.5],  # 常用图片的三通道均值，通常来说需要先对训练数据做统计，此处仅取中间值  \n",
    "    \"image_enhance_strategy\": {  # 图像增强相关策略  \n",
    "        \"need_distort\": True,  # 是否启用图像颜色增强  \n",
    "        \"need_rotate\": True,   # 是否需要增加随机角度  \n",
    "        \"need_crop\": True,      # 是否要增加裁剪  \n",
    "        \"need_flip\": True,      # 是否要增加水平随机翻转  \n",
    "        \"hue_prob\": 0.5,  \n",
    "        \"hue_delta\": 18,  \n",
    "        \"contrast_prob\": 0.5,  \n",
    "        \"contrast_delta\": 0.5,  \n",
    "        \"saturation_prob\": 0.5,  \n",
    "        \"saturation_delta\": 0.5,  \n",
    "        \"brightness_prob\": 0.5,  \n",
    "        \"brightness_delta\": 0.125  \n",
    "    },  \n",
    "    \"early_stop\": {  \n",
    "        \"sample_frequency\": 1,  \n",
    "        \"successive_limit\": 3,  \n",
    "        \"good_acc1\": 0.9625  \n",
    "    },  \n",
    "    \"rms_strategy\": {  \n",
    "        \"learning_rate\": 0.001, # 0.00125, # \n",
    "        \"lr_epochs\": [20, 40, 60, 80, 100],  \n",
    "        \"lr_decay\": [1, 0.5, 0.25, 0.1, 0.01, 0.002]  \n",
    "    },  \n",
    "    \"momentum_strategy\": {  \n",
    "        \"learning_rate\": 0.000625, #0.001,  \n",
    "        \"lr_epochs\": [20, 40, 60, 80, 100],  \n",
    "        \"lr_decay\": [1, 0.5, 0.25, 0.1, 0.01, 0.002]  \n",
    "    },  \n",
    "    \"sgd_strategy\": {  \n",
    "        \"learning_rate\": 0.00125, #0.001,  \n",
    "        \"lr_epochs\": [20, 40, 60, 80, 100],  \n",
    "        \"lr_decay\": [1, 0.5, 0.25, 0.1, 0.01, 0.002]  \n",
    "    },  \n",
    "    \"adam_strategy\": {  \n",
    "        \"learning_rate\": 0.002  \n",
    "    }, \n",
    "    \"adamax_strategy\": {  \n",
    "        \"learning_rate\": 0.00125  \n",
    "    }  \n",
    "}  \n",
    "\n",
    "def init_train_parameters():\n",
    "    \"\"\"\n",
    "    初始化训练参数，主要是初始化图片数量，类别数\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train_file_list = os.path.join(train_parameters['data_dir'], train_parameters['train_file_list'])\n",
    "    label_list = os.path.join(train_parameters['data_dir'], train_parameters['label_file'])\n",
    "    index = 0\n",
    "    with codecs.open(label_list, encoding='utf-8') as flist:\n",
    "        lines = [line.strip() for line in flist]\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            train_parameters['label_dict'][parts[1]] = int(parts[0])\n",
    "            index += 1\n",
    "        train_parameters['class_dim'] = index\n",
    "    with codecs.open(train_file_list, encoding='utf-8') as flist:\n",
    "        lines = [line.strip() for line in flist]\n",
    "        train_parameters['image_count'] = len(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **一、数据准备**\n",
    "\n",
    "（1）解压原始数据集\n",
    "\n",
    "（2）按照比例划分训练集与验证集\n",
    "\n",
    "（3）乱序，生成数据列表\n",
    "\n",
    "（4）构造训练数据集提供器和验证数据集提供器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unzip_data(src_path,target_path):\n",
    "    '''\n",
    "    解压原始数据集，将src_path路径下的zip包解压至target_path目录下\n",
    "    '''\n",
    "    if(not os.path.isdir(target_path + \"scenes\")):     \n",
    "        z = zipfile.ZipFile(src_path, 'r')\n",
    "        z.extractall(path=target_path)\n",
    "        z.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 一些简单的图像处理函数，用于深度学习数据增强（Data Augmentation）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def distort_image(img):\r\n",
    "    \"\"\"\r\n",
    "    图像增强\r\n",
    "    :param img:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    def random_brightness(img):\r\n",
    "        \"\"\"\r\n",
    "        随机亮度调整\r\n",
    "        :param img:\r\n",
    "        :return:\r\n",
    "        \"\"\"\r\n",
    "        prob = np.random.uniform(0, 1)\r\n",
    "        if prob < train_parameters['image_enhance_strategy']['brightness_prob']:\r\n",
    "            brightness_delta = train_parameters['image_enhance_strategy']['brightness_delta']\r\n",
    "            delta = np.random.uniform(-brightness_delta, brightness_delta) + 1\r\n",
    "            img = ImageEnhance.Brightness(img).enhance(delta)\r\n",
    "        return img\r\n",
    "\r\n",
    "    def random_contrast(img):\r\n",
    "        \"\"\"\r\n",
    "        随机对比度调整\r\n",
    "        :param img:\r\n",
    "        :return:\r\n",
    "        \"\"\"\r\n",
    "        prob = np.random.uniform(0, 1)\r\n",
    "        if prob < train_parameters['image_enhance_strategy']['contrast_prob']:\r\n",
    "            contrast_delta = train_parameters['image_enhance_strategy']['contrast_delta']\r\n",
    "            delta = np.random.uniform(-contrast_delta, contrast_delta) + 1\r\n",
    "            img = ImageEnhance.Contrast(img).enhance(delta)\r\n",
    "        return img\r\n",
    "    \r\n",
    "    def random_saturation(img):\r\n",
    "        \"\"\"\r\n",
    "        随机饱和度调整\r\n",
    "        :param img:\r\n",
    "        :return:\r\n",
    "        \"\"\"\r\n",
    "        prob = np.random.uniform(0, 1)\r\n",
    "        if prob < train_parameters['image_enhance_strategy']['saturation_prob']:\r\n",
    "            saturation_delta = train_parameters['image_enhance_strategy']['saturation_delta']\r\n",
    "            delta = np.random.uniform(-saturation_delta, saturation_delta) + 1\r\n",
    "            img = ImageEnhance.Color(img).enhance(delta)\r\n",
    "        return img\r\n",
    "\r\n",
    "    def random_hue(img):\r\n",
    "        \"\"\"\r\n",
    "        随机色调整\r\n",
    "        :param img:\r\n",
    "        :return:\r\n",
    "        \"\"\"\r\n",
    "        prob = np.random.uniform(0, 1)\r\n",
    "        if prob < train_parameters['image_enhance_strategy']['hue_prob']:\r\n",
    "            hue_delta = train_parameters['image_enhance_strategy']['hue_delta']\r\n",
    "            delta = np.random.uniform(-hue_delta, hue_delta)\r\n",
    "            img_hsv = np.array(img.convert('HSV'))\r\n",
    "            img_hsv[:, :, 0] = img_hsv[:, :, 0] + delta\r\n",
    "            img = Image.fromarray(img_hsv, mode='HSV').convert('RGB')\r\n",
    "        return img\r\n",
    "        \r\n",
    "    ops = [random_brightness, random_contrast, random_saturation, random_hue]    \r\n",
    "    np.random.shuffle(ops) \r\n",
    "    img = ops[0](img)\r\n",
    "    img = ops[1](img)\r\n",
    "    img = ops[2](img)\r\n",
    "    img = ops[3](img)\r\n",
    "    return img\r\n",
    "\r\n",
    "def random_crop(img, scales=[0.3, 1.0], max_ratio=2.0, max_trial=50):\r\n",
    "    \"\"\"\r\n",
    "    随机裁剪\r\n",
    "    :param img:\r\n",
    "    :param scales:\r\n",
    "    :param max_ratio:\r\n",
    "    :param constraints:\r\n",
    "    :param max_trial:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    if random.random() > 0.6:\r\n",
    "        return img\r\n",
    "\r\n",
    "    w, h = img.size\r\n",
    "    crops = [(0, 0, w, h)]\r\n",
    "\r\n",
    "    while crops:\r\n",
    "        crop = crops.pop(np.random.randint(0, len(crops)))\r\n",
    "        img = img.crop((crop[0], crop[1], crop[0] + crop[2],\r\n",
    "                        crop[1] + crop[3])).resize(img.size, Image.LANCZOS)\r\n",
    "        return img\r\n",
    "    return img\r\n",
    "\r\n",
    "def random_expand(img, keep_ratio=True):\r\n",
    "    \"\"\"\r\n",
    "    随机扩张\r\n",
    "    :param img:\r\n",
    "    :param keep_ratio:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    if np.random.uniform(0, 1) < train_parameters['image_enhance_strategy']['expand_prob']:\r\n",
    "        return img\r\n",
    "\r\n",
    "    max_ratio = train_parameters['image_enhance_strategy']['expand_max_ratio']\r\n",
    "    w, h = img.size\r\n",
    "    c = 3\r\n",
    "    ratio_x = random.uniform(1, max_ratio)\r\n",
    "    if keep_ratio:\r\n",
    "        ratio_y = ratio_x\r\n",
    "    else:\r\n",
    "        ratio_y = random.uniform(1, max_ratio)\r\n",
    "    oh = int(h * ratio_y)\r\n",
    "    ow = int(w * ratio_x)\r\n",
    "    off_x = random.randint(0, ow -w)\r\n",
    "    off_y = random.randint(0, oh -h)\r\n",
    "\r\n",
    "    out_img = np.zeros((oh, ow, c), np.uint8)\r\n",
    "    for i in range(c):\r\n",
    "        out_img[:, :, i] = train_parameters['mean_rgb'][i]\r\n",
    "\r\n",
    "    out_img[off_y: off_y + h, off_x: off_x + w, :] = img\r\n",
    "\r\n",
    "    return Image.fromarray(out_img)\r\n",
    "\r\n",
    "def random_flip(img, thresh=0.5):\r\n",
    "    \"\"\"\r\n",
    "    随机翻转\r\n",
    "    :param img:\r\n",
    "    :param thresh:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    if random.random() > thresh:\r\n",
    "        img = img.transpose(Image.FLIP_LEFT_RIGHT)\r\n",
    "\r\n",
    "    return img\r\n",
    "\r\n",
    "def rotate_image(img, thresh=0.5):\r\n",
    "    \"\"\"\r\n",
    "    图像增强，增加随机旋转角度\r\n",
    "    \"\"\"\r\n",
    "    if random.random() > thresh:\r\n",
    "        angle = np.random.randint(-14, 15)\r\n",
    "        img = img.rotate(angle)\r\n",
    "\r\n",
    "    return img\r\n",
    "\r\n",
    "\r\n",
    "def preprocess(img, mode='train'):\r\n",
    "    \"\"\"\r\n",
    "    preprocess，图像增强预处理\r\n",
    "    :param img:\r\n",
    "    :param mode:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    # 在线增强模式和离线增强模式可以叠加使用，但是个人不建议一开始就用，样本文件数量多一些的话，耗时太久了。\r\n",
    "    # mode == 'train'，训练模式下才进行在线图像增强    \r\n",
    "    if mode == 'train':\r\n",
    "        if train_parameters[\"image_enhance_strategy\"][\"need_distort\"]:\r\n",
    "            img = distort_image(img)\r\n",
    "        if train_parameters[\"image_enhance_strategy\"]['need_rotate']:\r\n",
    "            img = rotate_image(img, thresh=0.5)                                     \r\n",
    "        if train_parameters[\"image_enhance_strategy\"][\"need_crop\"]:\r\n",
    "            img = random_crop(img)                 \r\n",
    "        if train_parameters[\"image_enhance_strategy\"][\"need_flip\"]:         \r\n",
    "            img = random_flip(img)\r\n",
    "        if train_parameters[\"image_enhance_strategy\"][\"need_expand\"]:\r\n",
    "            img = random_expand(img)    \r\n",
    "    return img  \r\n",
    "\r\n",
    "\r\n",
    "def distort_color(img):\r\n",
    "    \"\"\"\r\n",
    "    概率的图像增强\r\n",
    "    :param img:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    prob = np.random.uniform(0, 1)\r\n",
    "    # Apply different distort order\r\n",
    "    if prob < 0.35:\r\n",
    "        img = random_brightness(img)\r\n",
    "        img = random_contrast(img)\r\n",
    "        img = random_saturation(img)\r\n",
    "        img = random_hue(img)\r\n",
    "    elif prob < 0.7:\r\n",
    "        img = random_brightness(img)\r\n",
    "        img = random_saturation(img)\r\n",
    "        img = random_hue(img)\r\n",
    "        img = random_contrast(img)\r\n",
    "    return img\r\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 预处理数据，将其转化为标准格式。同时将数据拆分成两份，以便训练和计算\n",
    "# 数据集保存到'dataset/'目录中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 预处理数据，将其转化为标准格式。同时将数据拆分成两份，以便训练和计算预估准确率 \n",
    "import codecs   \n",
    "import os   \n",
    "import random   \n",
    "import shutil   \n",
    "import json\n",
    "from PIL import Image   \n",
    "\n",
    "\n",
    "train_ratio = 9.0/ 10   \n",
    "   \n",
    "dataset_dstdir = 'dataset/'   \n",
    "train_file_dir = 'dataset/train/'   \n",
    "class_list = [c for c in os.listdir(train_file_dir) if os.path.isdir(os.path.join(train_file_dir, c)) and not c.endswith('Set') and not c.startswith('.')]   \n",
    "class_list.sort() \n",
    "class_list.sort(key = lambda x:int(x[:])) ##目录名按数字排序\n",
    "#print('class_list=',class_list)   \n",
    "\n",
    "# json.load读取\n",
    "with open(os.path.join(dataset_dstdir, 'garbage_dict.json'), 'r') as f:\n",
    "    class_dict = json.load(f)\n",
    "print('class_dict=',class_dict)\n",
    "\n",
    "train_image_dir = os.path.join(dataset_dstdir, \"trainImageSet\")   \n",
    "if not os.path.exists(train_image_dir):   \n",
    "    os.makedirs(train_image_dir)   \n",
    "for class_dir in class_list:\n",
    "    class_path = os.path.join(train_image_dir,class_dir)\n",
    "    if not os.path.exists(class_path):   \n",
    "        os.makedirs(class_path)   \n",
    "       \n",
    "evals_image_dir = os.path.join(dataset_dstdir, \"evalsImageSet\")   \n",
    "if not os.path.exists(evals_image_dir):   \n",
    "    os.makedirs(evals_image_dir)   \n",
    "for class_dir in class_list:\n",
    "    class_path = os.path.join(evals_image_dir,class_dir)\n",
    "    if not os.path.exists(class_path):   \n",
    "        os.makedirs(class_path)      \n",
    "\n",
    "train_list_filename = os.path.join(dataset_dstdir, \"train_list.txt\")\n",
    "train_file = codecs.open(train_list_filename, 'w')   \n",
    "evals_list_filename = os.path.join(dataset_dstdir, \"evals_list.txt\")\n",
    "evals_file = codecs.open(evals_list_filename, 'w')   \n",
    "label_list_filename = os.path.join(dataset_dstdir, \"label_list.txt\")\n",
    "with codecs.open(label_list_filename, \"w\") as label_file:   \n",
    "    label_id = 0   \n",
    "    for class_dir in class_list:   \n",
    "        #\n",
    "        label_file.write(\"{0}\\t{1}\\n\".format(label_id, class_dict[class_dir]))   \n",
    "        #\n",
    "        image_path_pre = os.path.join(train_file_dir, class_dir)   \n",
    "        train_path_dst = os.path.join(train_image_dir, class_dir)   \n",
    "        evals_path_dst = os.path.join(evals_image_dir, class_dir)   \n",
    "        #print(image_path_pre, train_path_dst,evals_path_dst)\n",
    "        #break\n",
    "        file_list = os.listdir(image_path_pre)\n",
    "        random.shuffle(file_list)\n",
    "        for file in file_list:   \n",
    "            try:\n",
    "                #img = Image.open(os.path.join(image_path_pre, file))   \n",
    "                #print(image_path_pre, file, (os.path.join(image_path_pre, file), os.path.join(train_path_dst, file)), (os.path.join(image_path_pre, file), os.path.join(evals_path_dst, file)))\n",
    "                #break\n",
    "                if random.uniform(0, 1) > train_ratio:   \n",
    "                    shutil.copyfile(os.path.join(image_path_pre, file), os.path.join(evals_path_dst, file))   \n",
    "                    evals_file.write(\"{0}\\t{1}\\n\".format(os.path.join(evals_path_dst, file), label_id))   \n",
    "                else:\n",
    "                    shutil.copyfile(os.path.join(image_path_pre, file), os.path.join(train_path_dst, file))   \n",
    "                    train_file.write(\"{0}\\t{1}\\n\".format(os.path.join(train_path_dst, file), label_id))                       \n",
    "\n",
    "                    \"\"\"\n",
    "                    离线数据增强，并保存到训练列表文件中    \n",
    "                    \"\"\"    \n",
    "            except Exception as e:   \n",
    "                #打印出来看是啥问题\n",
    "                print(e)\n",
    "                pass   \n",
    "                # 可能会有一些文件打不开，此处需要稍作清洗   \n",
    "        print('label_id=%d have porcessed.' % label_id)\n",
    "        label_id += 1   \n",
    "        #break              \n",
    "\n",
    "train_file.close()   \n",
    "evals_file.close()\n",
    "\n",
    "print('列表已生成:', train_list_filename,evals_list_filename,label_list_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 构造数据提供器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import ast\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.layer_helper import LayerHelper\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, BatchNorm, Linear\n",
    "from paddle.fluid.dygraph.base import to_variable\n",
    "from paddle.fluid import framework\n",
    "from paddle.fluid.param_attr import ParamAttr\n",
    "\n",
    "init_train_parameters()\n",
    "\n",
    "# reader\n",
    "def custom_image_reader(file_list,mode):\n",
    "    '''\n",
    "    自定义reader\n",
    "    '''\n",
    "    def reader():\n",
    "        with open(file_list, 'r') as f:\n",
    "            lines = [line.strip() for line in f]\n",
    "            random.shuffle(lines)\n",
    "            for line in lines:\n",
    "                if mode == 'train' or mode == 'eval':\n",
    "                    img_path, lab = line.strip().split('\\t')\n",
    "                    img = Image.open(img_path) \n",
    "                    if img.mode != 'RGB': \n",
    "                        img = img.convert('RGB') \n",
    "                    #使用在线增强方式，不用的话，把下一段代码注释掉\n",
    "                    #验证模式下不用增强，所以加了一个工作模式条件判断\n",
    "                    \"\"\"                    \n",
    "                    if mode == 'train': \n",
    "                        #在线增强方式：\n",
    "                        if (train_parameters[\"use_image_enhance\"]):\n",
    "                            img = preprocess(img, mode)  #只有在'train'模式下才执行图像增强\n",
    "                    \"\"\"\n",
    "                    #图像缩放到指定大小，VGG是3x224x224\n",
    "                    img = img.resize((224, 224), Image.ANTIALIAS)\n",
    "                    img = np.array(img).astype('float32') \n",
    "                    #图像数据按照所需要的格式重新排列\n",
    "                    img = img.transpose((2, 0, 1))  # HWC to CHW \n",
    "                    img = img/255.0                   # 像素值归一化 \n",
    "                    yield img, int(lab) \n",
    "                elif mode == 'test':\n",
    "                    img_path = line.strip()\n",
    "                    img = Image.open(img_path)\n",
    "                    img = img.resize((224, 224), Image.ANTIALIAS)\n",
    "                    img = np.array(img).astype('float32') \n",
    "                    img = img.transpose((2, 0, 1))  # HWC to CHW \n",
    "                    img = img/255.0                   # 像素值归一化                     \n",
    "                    yield img                    \n",
    "    return reader\n",
    "\n",
    "'''\n",
    "构造数据提供器，\n",
    "训练集和验证集调用同样的函数，但是工作模式这个参数不一样。\n",
    "'''\n",
    "train_file_list = os.path.join(train_parameters['data_dir'], train_parameters[\"train_file_list\"])\n",
    "train_reader = paddle.batch(custom_image_reader(train_file_list, 'train'),\n",
    "                                    batch_size=train_parameters['train_batch_size'],\n",
    "                                    drop_last=True)\n",
    "evals_file_list = os.path.join(train_parameters['data_dir'], train_parameters[\"evals_file_list\"])\n",
    "evals_reader = paddle.batch(custom_image_reader(evals_file_list, 'eval'),\n",
    "                                   batch_size=train_parameters['train_batch_size'],\n",
    "                                   drop_last=True)\n",
    "\n",
    "\n",
    "def eval_net(reader, model):\n",
    "    acc_set = []\n",
    "    \n",
    "    for batch_id, data in enumerate(reader()):\n",
    "        dy_x_data = np.array([x[0] for x in data]).astype('float32')\n",
    "        y_data = np.array([x[1] for x in data]).astype('int')\n",
    "        y_data = y_data[:, np.newaxis]\n",
    "        img = fluid.dygraph.to_variable(dy_x_data)\n",
    "        label = fluid.dygraph.to_variable(y_data)\n",
    "        label.stop_gradient = True\n",
    "        prediction, acc = model(img, label)\n",
    "\n",
    "        acc_set.append(float(acc.numpy()))\n",
    "\n",
    "        # get test acc and loss\n",
    "    acc_val_mean = np.array(acc_set).mean()\n",
    "\n",
    "    return acc_val_mean   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 训练过程中loss/acc的显示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "all_train_iter=0\n",
    "all_train_iters=[]\n",
    "all_train_costs=[]\n",
    "all_train_accs=[]\n",
    "\n",
    "def draw_train_process(title,iters,costs,accs,label_cost,lable_acc):\n",
    "    plt.title(title, fontsize=24)\n",
    "    plt.xlabel(\"iter\", fontsize=20)\n",
    "    plt.ylabel(\"loss/acc\", fontsize=20)\n",
    "    plt.plot(iters, costs,color='red',label=label_cost) \n",
    "    plt.plot(iters, accs,color='green',label=lable_acc) \n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def draw_process(title,color,iters,data,label):\n",
    "    plt.title(title, fontsize=24)\n",
    "    plt.xlabel(\"iter\", fontsize=20)\n",
    "    plt.ylabel(label, fontsize=20)\n",
    "    plt.plot(iters, data,color=color,label=label) \n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **二、模型配置**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/9ca0744272b0449186f766afcabadd598e24679088a4438dafede05a71b7c141)\n",
    "\n",
    "VGG的核心是五组卷积操作，每两组之间做Max-Pooling空间降维。同一组内采用多次连续的3X3卷积，卷积核的数目由较浅组的64增多到最深组的512，同一组内的卷积核数目是一样的。卷积之后接两层全连接层，之后是分类层。由于每组内卷积层的不同，有11、13、16、19层这几种模型，上图展示一个16层的网络结构。\n",
    "# 在以下cell中完成VGG网络的定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "VGG网络的定义，AIStudio 官方项目：用PaddlePaddle实现图像分类-VGG（动态图版）\n",
    "    Fork源：https://aistudio.baidu.com/aistudio/projectdetail/204999\n",
    "\"\"\"\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, BatchNorm, Linear\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "VGG网络\n",
    "\"\"\"\n",
    "\n",
    "class ConvBlock(fluid.dygraph.Layer):\n",
    "    \"\"\"\n",
    "    卷积+池化\n",
    "    \"\"\"\n",
    "    def __init__(self, name_scope, num_channels, num_filters, groups):\n",
    "        \"\"\"构造函数\"\"\"\n",
    "        super(ConvBlock, self).__init__(name_scope)\n",
    "\n",
    "        self._conv2d_list = []\n",
    "        init_num_channels = num_channels\n",
    "        for i in range(groups):\n",
    "            conv2d = self.add_sublayer(\n",
    "                'bb_%d' % i,\n",
    "                fluid.dygraph.Conv2D(\n",
    "                    init_num_channels, num_filters=num_filters, filter_size=3,\n",
    "                    stride=1, padding=1, act='relu'\n",
    "                )\n",
    "            )\n",
    "            self._conv2d_list.append(conv2d)\n",
    "            init_num_channels = num_filters\n",
    "\n",
    "        self._pool = fluid.dygraph.Pool2D(\n",
    "            pool_size=2, pool_type='max', pool_stride=2\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"前向计算\"\"\"\n",
    "        x = inputs\n",
    "        for conv in self._conv2d_list:\n",
    "            x = conv(x)\n",
    "        x = self._pool(x)\n",
    "        return x\n",
    "\n",
    "class VGGNet(fluid.dygraph.Layer):\n",
    "    \"\"\"\n",
    "    VGG网络\n",
    "    \"\"\"\n",
    "    def __init__(self, name_scope, layers=16, class_dim=1000):\n",
    "        \"\"\"\n",
    "        构造函数\n",
    "        :param name_scope:   命名空间\n",
    "        :param layers:       具体的层数如VGG-16、VGG-19等\n",
    "        \"\"\"\n",
    "        super(VGGNet, self).__init__(name_scope)\n",
    "        self.vgg_spec = {\n",
    "            11: ([1, 1, 2, 2, 2]),\n",
    "            13: ([2, 2, 2, 2, 2]),\n",
    "            16: ([2, 2, 3, 3, 3]),\n",
    "            19: ([2, 2, 4, 4, 4])\n",
    "        }\n",
    "        assert layers in self.vgg_spec.keys(), \\\n",
    "            \"supported layers are {} but input layer is {}\".format(self.vgg_spec.keys(), layers)\n",
    "\n",
    "        nums = self.vgg_spec[layers]\n",
    "        self.conv1 = ConvBlock(self.full_name(), num_channels=3, num_filters=64, groups=nums[0])\n",
    "        self.conv2 = ConvBlock(self.full_name(), num_channels=64, num_filters=128, groups=nums[1])\n",
    "        self.conv3 = ConvBlock(self.full_name(), num_channels=128, num_filters=256, groups=nums[2])\n",
    "        self.conv4 = ConvBlock(self.full_name(), num_channels=256, num_filters=512, groups=nums[3])\n",
    "        self.conv5 = ConvBlock(self.full_name(), num_channels=512, num_filters=512, groups=nums[4])\n",
    "\n",
    "        fc_dim = 4096\n",
    "        self.fc1 = fluid.dygraph.Linear(input_dim=25088, output_dim=fc_dim, act='relu')\n",
    "        self.fc2 = fluid.dygraph.Linear(input_dim=fc_dim, output_dim=fc_dim, act='relu')\n",
    "        self.out = fluid.dygraph.Linear(input_dim=fc_dim, output_dim=class_dim, act='softmax')\n",
    "\n",
    "    def forward(self, inputs, label=None):\n",
    "        \"\"\"前向计算\"\"\"\n",
    "        out = self.conv1(inputs)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv5(out)\n",
    "\n",
    "        out = fluid.layers.reshape(out, [-1, 25088])\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        out = fluid.layers.dropout(out, dropout_prob=0.5)\n",
    "\n",
    "        out = self.fc2(out)\n",
    "        out = fluid.layers.dropout(out, dropout_prob=0.5)\n",
    "\n",
    "        out = self.out(out)\n",
    "        \n",
    "        if label is not None:\n",
    "            acc = fluid.layers.accuracy(input=out, label=label)\n",
    "            return out, acc\n",
    "        else:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **三、模型训练 && 四、模型评估**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 参考项目代码，自己写了一个优化器配置函数（比较粗糙，赶时间为了完成作业）\n",
    "# 提高最后精度的措施：\n",
    "# 1、加了L2正则化：[L2Decay实现L2权重衰减正则化，用于模型训练，有助于防止模型对训练数据过拟合]\n",
    "#    我的代码里取l2_decay = 1.2e-4。缺省是1e-4\n",
    "# 2、学习率随训练次数衰减：[在训练模型时，建议一边进行训练一边降低学习率] \n",
    "#    我在调不动时后再用，最后效果还能再提高一点，cosine_decay，https://www.paddlepaddle.org.cn/documentation/docs/zh/api_cn/layers_cn/cosine_decay_cn.html#cosine-decay\n",
    "#    前期训练时候用的是常值（初始学习率不变），或者对初始学习率进行分段衰减\n",
    "#    piecewise_decay，https://www.paddlepaddle.org.cn/documentation/docs/zh/api_cn/layers_cn/piecewise_decay_cn.html#piecewise-decay  \n",
    "\n",
    "print(train_parameters)\n",
    "momentum_rate = 0.9\n",
    "l2_decay = 1.2e-4\n",
    "\n",
    "def optimizer_setting(params, paramsList):\n",
    "    total_images = params[\"image_count\"]\n",
    "    ls = params[\"train_batch_size\"]\n",
    "    step = int(math.ceil(float(total_images) / batch_size))\n",
    "    \n",
    "    #为了调试方便，这里直接赋值初始学习率\n",
    "    learning_rate = 0.00125  \n",
    "    #实际取值需要根据调试要求选取\n",
    "    lr = learning_rate\n",
    "\n",
    "    num_epochs = params[\"num_epochs\"]\n",
    "    regularization=fluid.regularizer.L2Decay(l2_decay)\n",
    "    learning_rate=fluid.layers.cosine_decay(learning_rate=lr, step_each_epoch=step, epochs=num_epochs)\n",
    "\n",
    "    optimizer=fluid.optimizer.AdamaxOptimizer(learning_rate=learning_rate, regularization=regularization, parameter_list=paramsList)\n",
    "\n",
    "    return optimizer    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\r\n",
    "模型训练\r\n",
    "'''\r\n",
    "epochs_num = train_parameters[\"num_epochs\"]\r\n",
    "batch_size = train_parameters[\"train_batch_size\"]\r\n",
    "total_images=train_parameters[\"image_count\"]\r\n",
    "stepsnumb = int(math.ceil(float(total_images) / batch_size))        \r\n",
    "\r\n",
    "with fluid.dygraph.guard(place = fluid.CUDAPlace(0)):   #使用GPU进行训练\r\n",
    "#with fluid.dygraph.guard():                            #使用CPU进行训练\r\n",
    "    print(train_parameters['class_dim'])\r\n",
    "    print(train_parameters['label_dict'])\r\n",
    "\r\n",
    "    best_acc = 0    \r\n",
    "    best_epc = -1 \r\n",
    "    eval_epchnumber = 0\r\n",
    "    all_eval_avgacc = []\r\n",
    "    all_eval_iters = []\r\n",
    "\r\n",
    "    model = VGGNet(\"vgg_net\", train_parameters[\"network_vgg\"][\"layer\"], train_parameters[\"class_dim\"])\r\n",
    "\r\n",
    "    if True:        \r\n",
    "        try:\r\n",
    "            if os.path.exists('MyVGG_best.pdparams'):\r\n",
    "                print('try model file MyVGG_best. Loading...')\r\n",
    "                model_dict, _ = fluid.load_dygraph('MyVGG_best')        \r\n",
    "            else:\r\n",
    "                print('try model file MyVGG. Loading...')\r\n",
    "                model_dict, _ = fluid.load_dygraph('MyVGG')        \r\n",
    "            model.load_dict(model_dict) #加载模型参数  \r\n",
    "            print('model initialization finished.')\r\n",
    "        except Exception as e:\r\n",
    "            print('model initialization error found:')                 \r\n",
    "            print(e)               \r\n",
    "\r\n",
    "    #后面代码会切换工作模式\r\n",
    "    model.train() #训练模式\r\n",
    "\r\n",
    "    #定义优化方法\r\n",
    "    optimizer = optimizer_setting(train_parameters, model.parameters())\r\n",
    "    \r\n",
    "    #epochs_num = 1\r\n",
    "     #开始训练\r\n",
    "    for epoch_num in range(epochs_num):\r\n",
    "        model.train() #训练模式\r\n",
    "         #从train_reader中获取每个批次的数据\r\n",
    "        for batch_id, data in enumerate(train_reader()):\r\n",
    "            dy_x_data = np.array([x[0] for x in data]).astype('float32').reshape(-1, 3,224,224)\r\n",
    "            y_data = np.array([x[1] for x in data]).astype('int64').reshape(-1,1)                               \r\n",
    "\r\n",
    "            #将Numpy转换为DyGraph接收的输入\r\n",
    "            img = fluid.dygraph.to_variable(dy_x_data)\r\n",
    "            label = fluid.dygraph.to_variable(y_data)\r\n",
    "\r\n",
    "            out,acc = model(img,label)\r\n",
    "            loss = fluid.layers.cross_entropy(out, label)\r\n",
    "            avg_loss = fluid.layers.mean(loss)\r\n",
    "\r\n",
    "            #使用backward()方法可以执行反向网络\r\n",
    "            avg_loss.backward()\r\n",
    "            optimizer.minimize(avg_loss)             \r\n",
    "            #将参数梯度清零以保证下一轮训练的正确性\r\n",
    "            model.clear_gradients()            \r\n",
    "\r\n",
    "            all_train_iter=all_train_iter+train_parameters['train_batch_size']\r\n",
    "            all_train_iters.append(all_train_iter)\r\n",
    "            all_train_costs.append(loss.numpy()[0])\r\n",
    "            all_train_accs.append(acc.numpy()[0])\r\n",
    "                \r\n",
    "            # 周期性输出显示信息\r\n",
    "            if batch_id % 100 == 0 or batch_id == stepsnumb-1:\r\n",
    "                print(\"epoch %3d step %4d: loss: %f, acc: %f\" % (epoch_num, batch_id, avg_loss.numpy(), acc.numpy()))\r\n",
    "\r\n",
    "        if epoch_num % 1 == 0 or epoch_num == epochs_num-1:\r\n",
    "            model.eval()      \r\n",
    "            accs = []\r\n",
    "            for batch_id, data in enumerate(evals_reader()):\r\n",
    "                dy_x_data = np.array([x[0] for x in data]).astype('float32').reshape(-1,3,224,224)\r\n",
    "                y_data = np.array([x[1] for x in data]).astype('int').reshape(-1,1)\r\n",
    "        \r\n",
    "                img = fluid.dygraph.to_variable(dy_x_data)\r\n",
    "                label = fluid.dygraph.to_variable(y_data)\r\n",
    "\r\n",
    "                out, acc = model(img, label)\r\n",
    "                lab = np.argsort(out.numpy())\r\n",
    "                accs.append(acc.numpy()[0])    \r\n",
    "            epoch_acc = np.mean(accs)            \r\n",
    "            print('  train_pass:%d,avg_acc=%f' % (epoch_num,epoch_acc))  \r\n",
    "            eval_epchnumber = epoch_num\r\n",
    "            all_eval_avgacc.append(eval_epchnumber)\r\n",
    "            all_eval_iters.append(epoch_acc)\r\n",
    "                \r\n",
    "            if best_acc < epoch_acc:  \r\n",
    "                best_epc=epoch_num                                      \r\n",
    "                best_acc=epoch_acc\r\n",
    "                fluid.save_dygraph(model.state_dict(),'MyVGG_best')#保存模型\r\n",
    "                print('    current best_acc=%f in No.%d epoch' % (best_acc,best_epc)) \r\n",
    "                print('    MyVGG_best模型已保存')\r\n",
    "                with open('beast_acc_Vgg.txt', \"w\") as f:\r\n",
    "                    f.write(str(best_acc))\r\n",
    "                fluid.dygraph.save_dygraph(model.state_dict(), \"save_dir/model_best\")\r\n",
    "                fluid.dygraph.save_dygraph(optimizer.state_dict(), \"save_dir/model_best\")    \r\n",
    "\r\n",
    "            #显示\r\n",
    "            draw_train_process(\"training\",all_train_iters,all_train_costs,all_train_accs,\"trainning loss\",\"trainning acc\")    \r\n",
    "\r\n",
    "    draw_train_process(\"training\",all_train_iters,all_train_costs,all_train_accs,\"trainning loss\",\"trainning acc\")  \r\n",
    "    draw_process(\"trainning loss\",\"red\",all_train_iters,all_train_costs,\"trainning loss\")\r\n",
    "    draw_process(\"trainning acc\",\"green\",all_train_iters,all_train_accs,\"trainning acc\")  \r\n",
    "    \r\n",
    "    #保存模型参数\r\n",
    "    fluid.save_dygraph(model.state_dict(), \"MyVGG\")   \r\n",
    "    print('MyVGG模型已保存')\r\n",
    "    print(\"Final loss: {}\".format(avg_loss.numpy()))\r\n",
    "    #fluid.dygraph.save_dygraph(model.state_dict(), \"save_dir/model\")\r\n",
    "    #fluid.dygraph.save_dygraph(optimizer.state_dict(), \"save_dir/model\")    \r\n",
    "    with open('acc_VGG.txt', \"w\") as f:\r\n",
    "        f.write(str(epoch_acc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\r\n",
    "模型校验\r\n",
    "'''\r\n",
    "with fluid.dygraph.guard(place = fluid.CUDAPlace(0)):\r\n",
    "    model = VGGNet(\"vgg_net\", train_parameters[\"network_vgg\"][\"layer\"], train_parameters[\"class_dim\"])\r\n",
    "    model_dict, _ = fluid.load_dygraph(\"MyVGG_best\")    \r\n",
    "    #model_dict, _ = fluid.dygraph.load_dygraph(\"save_dir/model_best\")\r\n",
    "    model.load_dict(model_dict)\r\n",
    "    model.eval()\r\n",
    "\r\n",
    "    accs = []\r\n",
    "    for batch_id, data in enumerate(evals_reader()):\r\n",
    "        dy_x_data = np.array([x[0] for x in data]).astype('float32').reshape(-1,3,224,224)\r\n",
    "        y_data = np.array([x[1] for x in data]).astype('int').reshape(-1,1)\r\n",
    "        \r\n",
    "        img = fluid.dygraph.to_variable(dy_x_data)\r\n",
    "        label = fluid.dygraph.to_variable(y_data)\r\n",
    "\r\n",
    "        out, acc = model(img, label)\r\n",
    "        lab = np.argsort(out.numpy())\r\n",
    "        accs.append(acc.numpy()[0])\r\n",
    "\r\n",
    "    avg_acc = np.mean(accs)\r\n",
    "#print(np.mean(accs))\r\n",
    "print(\"模型校验avg_acc=\",avg_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **五、模型预测**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import codecs\r\n",
    "from PIL import Image, ImageEnhance\r\n",
    "\r\n",
    "#打印出来看一下标签信息\r\n",
    "print('label_dic =',train_parameters['label_dict'])\r\n",
    "\r\n",
    "def load_image(img_path):\r\n",
    "    '''\r\n",
    "    预测图片预处理\r\n",
    "    '''\r\n",
    "    img = Image.open(img_path) \r\n",
    "    if img.mode != 'RGB': \r\n",
    "        img = img.convert('RGB') \r\n",
    "    img = img.resize((224, 224), Image.BILINEAR)\r\n",
    "    img = np.array(img).astype('float32') \r\n",
    "    img = img.transpose((2, 0, 1))  # HWC to CHW \r\n",
    "    img = img/255                # 像素值归一化 \r\n",
    "    return img\r\n",
    "\r\n",
    "'''\r\n",
    "模型预测\r\n",
    "'''\r\n",
    "with fluid.dygraph.guard():\r\n",
    "    model = VGGNet(\"vgg_net\", train_parameters[\"network_vgg\"][\"layer\"], train_parameters[\"class_dim\"])\r\n",
    "    model_dict, _ = fluid.load_dygraph(\"MyVGG_best\")    \r\n",
    "    #model_dict, _ = fluid.dygraph.load_dygraph(\"save_dir/model_best\")\r\n",
    "    model.load_dict(model_dict)\r\n",
    "    model.eval()  \r\n",
    "\r\n",
    "    # 目录路径\r\n",
    "    data_dir = train_parameters[\"data_dir\"]\r\n",
    "    infer_path = os.path.join(data_dir,\"test/\")\r\n",
    "\r\n",
    "    #展示预测图片\r\n",
    "    infer_imag=os.path.join(infer_path,'test1.jpg')\r\n",
    "    img = Image.open(infer_imag)\r\n",
    "    plt.imshow(img)          #根据数组绘制图像\r\n",
    "    plt.show()               #显示图像\r\n",
    "    print(\"demo演示：\", infer_imag)\r\n",
    "\r\n",
    "     #对预测图片进行预处理\r\n",
    "    #tests_file_list = train_parameters[\"tests_file_list\"]\r\n",
    "    tests_file_list = \"testpath.txt\"\r\n",
    "    file_list = os.path.join(data_dir,tests_file_list)\r\n",
    "    with codecs.open(file_list) as flist:\r\n",
    "        img_list = [line.strip() for line in flist]\r\n",
    "    infer_imgs = []        \r\n",
    "    for imgfn in img_list:\r\n",
    "        infer_imag=os.path.join(infer_path,imgfn)\r\n",
    "        infer_imgs.append(load_image(infer_imag))\r\n",
    "    infer_imgs = np.array(infer_imgs)\r\n",
    "\r\n",
    "    print(\"test开始\")\r\n",
    "    final_result_list = [] \r\n",
    "    for  i in range(len(infer_imgs)):\r\n",
    "        data = infer_imgs[i]\r\n",
    "        dy_x_data = np.array(data).astype('float32')\r\n",
    "        dy_x_data=dy_x_data[np.newaxis,:, : ,:]\r\n",
    "        img = fluid.dygraph.to_variable(dy_x_data)\r\n",
    "        out = model(img)\r\n",
    "        lab = np.argmax(out.numpy())  #argmax():返回最大数的索引        \r\n",
    "        final_result_list.append(lab)  \r\n",
    "\r\n",
    "    print(\"test存储结果\")\r\n",
    "    if True:\r\n",
    "        if True:\r\n",
    "            # 判断结果数量是否满足要求\r\n",
    "            saveFileName = 'final_result_vgg.txt'\r\n",
    "            with codecs.open(saveFileName,'w') as flist:\r\n",
    "                for i in range(len(final_result_list)):                    \r\n",
    "                    # 最后一行不要加'\\n'换行符\r\n",
    "                    if i != len(final_result_list)-1:\r\n",
    "                        flist.write(str(final_result_list[i])+\"\\n\")\r\n",
    "                    else:\r\n",
    "                        flist.write(str(final_result_list[i]))\r\n",
    "                if len(final_result_list)>0:\r\n",
    "                    print(saveFileName+' saved with %d records.' % len(final_result_list))\r\n",
    "                else:\r\n",
    "                    print('invalid record num.')   \r\n",
    "\r\n",
    "    print(\"test结束\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.8.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
